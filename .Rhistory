wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=10,oredred.colors=T)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=20,oredred.colors=T)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,oredred.colors=T)
pal<-brewer.pal(6,"Dark2")
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,oredred.colors=T,pal)
pal<-brewer.pal(600,"Dark2")
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,pal)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100, colors=brewer.pal(8, “Dark2”))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,“Dark2”))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark3"))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark1"))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark"))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),random.order=FALSE)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,use.r.layout=F)
windows()
windows()
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,use.r.layout=F)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE)
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,scale=c(8,16))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,scale=c(2,6))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,scale=c(0.5,2))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,scale=c(2,0.5))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,scale=c(10,5))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=100,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,scale=c(5,1))
wordcloud(words=Atlas.Shrugged$text,freq=Atlas.Shrugged$Freq,max.words=10,colors=brewer.pal(8,"Dark2"),rot.per=0.35,random.order=FALSE,scale=c(5,1))
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
text.df<-Atlas.Shrugged
word.cloud.funct<-function(text.df,no.words=5){
word.cloud<-wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=input$no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c(5,1))
return(word.cloud)
}
word.cloud.funct(text.df)
word.cloud.funct(text.df=text.df)
no.words=5
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=input$no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c(5,1))
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c(5,1))
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c(50,1))
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=50,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c(5,1))
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=50,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c(8,2))
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=50,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c(10,3))
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
test<-clean.word.count("https://cran.r-project.org/")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
name(text.df)
names(text.df)
as.character(text.df)
as.name(text.df)
as.character(bquote(text.df))
runApp(display.mode="showcase")
rm(list=ls())
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
filler.words<-read.Lines("./fillerwords.txt")
filler.words<-readLines("./fillerwords.txt")
filler.words<-readLines("./fillerwords.txt")
filler.words<-read.table("./fillerwords.txt")
View(filler.words)
class(filler.words)
filler.words$V2
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
MLK.speech.url<-"http://www.let.rug.nl/usa/documents/1951-/martin-luther-kings-i-have-a-dream-speech-august-28-1963.php"
text.df<-clean.word.count(MLK.speech.url)
##Function to get a dataframe of word counts.
clean.word.count<-function(url){
##Read in the text from the Gutenberg online library.
text<-readLines(url)
##Collpase the text into one long character vector.
text<-paste(text,collapse=" ")
##Get rid of numbers and punctuation. Make everything lower case.
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
##Split large character vector into substrings.
text<-strsplit(text,split=" ")
##Create a frequency table and make it into a dataframe.
##Get rid of the empty space count.
text.df<-as.data.frame(table(text))
text.df<-text.df[-(which(text.df[,1]==c(""))),]
##Checking that the words are in English.
text.df<-text.df[(text.df$text %in% dictionary),]
##Sort by count and turning text into a factor.
text.df<-text.df[order(text.df$Freq,decreasing=TRUE),]
text.df$text<-factor(text.df$text, levels = text.df$text)
return(text.df)
}
text.df<-clean.word.count(MLK.speech.url)
dictionary<-readLines("./dictionary.txt")
text.df<-clean.word.count(MLK.speech.url)
filler.rm=TRUE
if(filler.rm==TRUE)
{text.df<-text.df[-(text.df$text %in% filler.words$V2),]}
text.df$text %in% filler.words$V2
text.df[-(1:560),]
text.df[-(text.df$text %in% filler.words$V2),]
text.df[!(text.df$text %in% filler.words$V2),]
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
-wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c((7-no.words/50),(2-no.words/50)),
main="Word Cloud")
no.words=50
-wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c((7-no.words/50),(2-no.words/50)),
main="Word Cloud")
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c((7-no.words/50),(2-no.words/50)),
main="Word Cloud")
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c((7-no.words/50),(2-no.words/50)),
title="Word Cloud")
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c((7-no.words/50),(2-no.words/50)),
main="Word Cloud")
wordcloud(words=text.df$text,freq=text.df$Freq,
max.words=no.words,colors=brewer.pal(8,"Dark2"),
rot.per=0.35,random.order=FALSE,
scale=c((7-no.words/50),(2-no.words/50)))
title("Word Cloud")
runApp(display.mode="showcase")
library(shinyapps)
shinyapps::deployApp('./')
deployApp('./')
deployApp()
deployApp("./")
deployApp(appName="Wordcount Application")
getwd()
deployApp(getwd())
shinyapps::setAccountInfo(name='datadan01', token='A9F664675BF9767ED44A6E7B83C5B90B', secret='Ud+X+YGB4r9ilvGA6b92WtpGpVcxdVturQn7xhRY')
deployApp(appName="Wordcount Application")
shinyapps::setAccountInfo(name='datadan01',
token='A9F664675BF9767ED44A6E7B83C5B90B',
secret='Ud+X+YGB4r9ilvGA6b92WtpGpVcxdVturQn7xhRY')
deployApp(appName="Wordcount Application")
shinyapps::deployApp()
shinyapps::setAccountInfo(name='datadan01', token='A9F664675BF9767ED44A6E7B83C5B90B', secret='Ud+X+YGB4r9ilvGA6b92WtpGpVcxdVturQn7xhRY')
deployApp(appName="Wordcount Application")
shinyapps::setAccountInfo(name='datadan01', token='A9F664675BF9767ED44A6E7B83C5B90B', secret='Ud+X+YGB4r9ilvGA6b92WtpGpVcxdVturQn7xhRY')
library(rsconnect)
install.packages("rsconnect")
devtools::install_github("rstudio/rsconnect")
library(rsconnect)
deployApp()
shinyapps::setAccountInfo(name='datadan01',
token='A9F664675BF9767ED44A6E7B83C5B90B',
secret='Ud+X+YGB4r9ilvGA6b92WtpGpVcxdVturQn7xhRY')
deployApp()
R.wiki.page.url<-"https://en.wikipedia.org/w/index.php?title=R_(programming_language)&printable=yes"
clean.word.count<-function(url){
##Read in the text from the source.
content <- getURL(url)
text <- htmlParse(content, asText = TRUE)
##Collpase the text into one long character vector.
text<-paste(text,collapse=" ")
##Get rid of numbers and punctuation. Make everything lower case.
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
##Split large character vector into substrings.
text<-strsplit(text,split=" ")
##Create a frequency table and make it into a dataframe.
##Get rid of the empty space count.
text.df<-as.data.frame(table(text))
text.df<-text.df[-(which(text.df[,1]==c(""))),]
##Checking that the words are in English.
text.df<-text.df[(text.df$text %in% dictionary),]
##Sort by count and turning text into a factor.
text.df<-text.df[order(text.df$Freq,decreasing=TRUE),]
text.df$text<-factor(text.df$text, levels = text.df$text)
return(text.df)
}
test.df.2<-clean.word.count(R.wiki.page.url)
library(RCurl)
library(XML)
test.df.2<-clean.word.count(R.wiki.page.url)
content <- getURL(R.wiki.page.url)
text <- htmlParse(content, asText = TRUE)
text
text<-paste(text,collapse=" ")
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
text<-gsub("[[:punct:]]", "", text)
text <- xmlTreeParse(text)
url<-R.wiki.page.url
content <- getURL(url)
text <- htmlParse(content)
text <- xmlTreeParse(text)
content <- getURL(url)
text <- xmlTreeParse(content)
text<-paste(text,collapse=" ")
##Get rid of numbers and punctuation. Make everything lower case.
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
##Split large character vector into substrings.
text<-strsplit(text,split=" ")
##Create a frequency table and make it into a dataframe.
##Get rid of the empty space count.
text.df<-as.data.frame(table(text))
text.df<-text.df[-(which(text.df[,1]==c(""))),]
##Checking that the words are in English.
text.df<-text.df[(text.df$text %in% dictionary),]
##Sort by count and turning text into a factor.
text.df<-text.df[order(text.df$Freq,decreasing=TRUE),]
text.df$text<-factor(text.df$text, levels = text.df$text)
View(text.df)
deployApp()
library(shiny)
deployApp()
library(RCurl)
library(XML)
library(shiny)
deployApp()
library(shiny)
library(shinyapps)
deployApp()
runApp()
Atlas.Shrugged.url<-"https://raw.githubusercontent.com/blueconcept/Data-Compression-using-Huffman/master/Rand%2C%20Ayn%20-%20Atlas%20Shrugged.txt"
content <- getURL(Atlas.Shrugged.url)
class(content)
content <- getURL(url)
class(content)
class(getURL(MLK.speech.url))
str(getURL(MLK.speech.url))
grep("html",url)
grep("https",url)
grep("en.",url)
grepl("en.",url)
(grepl("https",url)==TRUE)&(grepl(".txt",url)==FALSE)
runApp()
text<-htmlToText(url)
library(XML)
text<-htmlToText(url)
library(RCurl)
{text<-htmlToText(url)
text<-htmlToText(url)
text <- xmlTreeParse(content)
head(text)
content <- getURL(url)
text <- tidyHTML(content)
text <- htmlTreeParse(text,userInternal=TRUE)
text <- xpathApply(html, "//body//text()[not(ancestor::script)]
[not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
text <- cat(unlist(text))
content <- getURL(url)
text <- tidyHTML(content)
text <- htmlTreeParse(text,userInternal=TRUE)
text <- xpathApply(html, "//body//text()[not(ancestor::script)]
[not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
content <- getURL(url)
text <- tidyHTML(content)
text <- htmlTreeParse(text,userInternal=TRUE)
text <- xpathApply(text, "//body//text()[not(ancestor::script)]
[not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
content <- getURL(url)
text <- tidyHTML(content)
install.packages("RTidyHTML")
install.packages("TidyHTML")
install.packages("RTidyHTML", repos = "http://www.omegahat.org/R", type="source")
content <- getURL(url)
text <- htmlTreeParse(text,userInternal=TRUE)
text <- xpathApply(text, "//body//text()[not(ancestor::script)]
[not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
text <- htmlTreeParse(text,userInternal=TRUE)
text <- htmlTreeParse(text)
text <- htmlTreeParse(text)
text <- getURL(url)
text <- htmlTreeParse(text)
text <- xpathApply(text, "//body//text()[not(ancestor::script)]
[not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
text <- xpathApply(xmlRoot(text), "//body//text()[not(ancestor::script)]
[not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
text<-htmlParse(url)
text<-xpathSApply(doc,'//div[@class="articleBody"]//p',xmlValue)
texd<-paste(text,collapse="\n")
text<-htmlParse(url)
text<-xpathSApply(text,'//div[@class="articleBody"]//p',xmlValue)
texd<-paste(text,collapse="\n")
text<-htmlParse(url)
text<-xpathSApply(text,'//div[@class="articleBody"]//p',xmlValue)
text<-paste(text,collapse="\n")
text
text<-htmlParse(url)
R.wiki.page.url<-"https://en.wikipedia.org/wiki/R_(programming_language)"
text<-htmlParse(url)
text<-xpathSApply(text,'//div[@class="articleBody"]//p',xmlValue)
text<-paste(text,collapse="\n")
url<-R.wiki.page.url
text<-htmlParse(url)
text
htmlParse(url,isURL=T)
text<-htmlTreeParse(url,isURL=T)
text<-htmlTreeParse("http://www.wsj.com/",isURL=T)
text<-xpathSApply(text,'//div[@class="articleBody"]//p',xmlValue)
text<-htmlParse(url,isURL=T)
text<-htmlParse("http://www.wsj.com/",isURL=T)
text
text<-xpathSApply(text,'//div[@class="articleBody"]//p',xmlValue)
install.packages("rvest")
library(rvest)
text <- readLines(url)
text <- readLines("http://stackoverflow.com/questions/26540485/readlines-does-not-read-from-https-url-when-called-from-systemrscript")
text <- readLines("http://www.wsj.com/")
text <- readLines("https://en.wikipedia.org/wiki/Apple")
text <- readLines("http://en.wikipedia.org/wiki/Apple")
text <- readLines("https://en.wikipedia.org/wiki/Apple")
url[4]
url[5]
url
class(url)
substr(url,4,5)
substr(url,5)
substr(url,5,5)
substr(url,5,5)<-""
url
substr(url,5,5)=="s"
sub("^....(.)",url)
sub("^....(.)","",url)
sub("^...(.)","",url)
sub("^..(.)","http",url)
sub("^....(.)","http",url)
runApp()
text <- readLines(url)
##Collpase the text into one long character vector.
text<-paste(text,collapse=" ")
##Get rid of numbers and punctuation. Make everything lower case.
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
text<-strsplit(text,split=" ")
text
text.df<-as.data.frame(table(text))
runApp()
text <- readLines(url)
text
test<-htmlParse(text)
test
test[1]
deployApp(appName = "WordCounter")
runApp()
runApp()
runApp()
deployApp(appName = "WordCounter")
runApp()
runApp()
runApp()
runApp()
deployApp(appName = "WordCounter")
runApp()
deployApp(appName = "WordCounter")
deployApp(appName = "WordCounter")
deployApp(appName = "WordCounter")
deployApp(appName = "WordCounter")
deployApp(appName = "WordCounter")
deployApp(appName = "WordCounter")
library(slidify)
install.packages("slidify")
install_github("slidify", "ramnathv")
require(devtools)
install_github("slidify", "ramnathv")
library(shiny)
runApp()
library(slidify)
author("Wordcount.App.Slides")
framework   : shower        # {io2012, html5slides, shower, dzslides, ...}
runApp(display.mode="showcase")
library(shiny)
library(shinyapps\)
library(shinyapps)
runApp(display.mode="showcase")
runApp(display.mode="showcase")
text <- readLines("http://www.archive.org/stream/anthem01250gut/anthm10z.txt")
##Get rid of numbers and punctuation. Make everything lower case.
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
##Split large character vector into substrings.
text<-strsplit(text,split=" ")
head(text)
summary(text)
table(text)
text <- c("Th1is. I!s A?n EXA,,.MPLE")
##Get rid of numbers and punctuation. Make everything lower case.
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
##Split large character vector into substrings.
text<-strsplit(text,split=" ")
text
text <- c("Th1is. I!s A?n EXA,,.MPLE 0of me3ssY! w0000r!!ds")
##Get rid of numbers and punctuation. Make everything lower case.
text<-gsub("[[:punct:]]", "", text)
text<-gsub("[[:digit:]]", "", text)
text<-tolower(text)
##Split large character vector into substrings.
text<-strsplit(text,split=" ")
text
publish(title = 'Wordcount Application', 'index.html', host = 'rpubs')
library(slidify)
publish(title = 'Wordcount Application', 'index.html', host = 'rpubs')
getwd()
publish(title = 'Wordcount Application', './index.html', host = 'rpubs')
publish(title = 'Wordcount Application', "./index.html", host = 'rpubs')
publish_rpubs("title"Wordcount Application, html_file = "index.html")
publish_rpubs(title=Wordcount Application", html_file = "index.html")
publish_rpubs(title="Wordcount Application", html_file = "index.html")
publish_rpubs(title="Wordcount Application", html_file = "index.html")
publish_github()
publish_github(user="datadan01",repo="https://github.com/DataDan01/Wordcount-App")
publish(title = 'wordcountapp', 'index.html', host = 'rpubs')
publish_rpubs(title = 'wordcountapp', 'index.html', host = 'rpubs')
publish_rpubs(title = 'wordcountapp', 'index.html')
publish_rpubs(title = 'wordcountapp', './index.html')
publish(user="datadan01",repo="https://github.com/DataDan01/Wordcount-App")
setwd("./Wordcount.App.Slides")
publish(user="datadan01",repo="https://github.com/DataDan01/Wordcount-App")
publish_github(user="datadan01",repo="https://github.com/DataDan01/Wordcount-App")
publish_rpubs(title = 'wordcountapp', 'index.html')
publish_rpubs(title = 'wordcountapp', html_file='index.html')
find.package("RCurl")
library(RCurl)
publish_rpubs(title = 'wordcountapp', html_file='index.html')
publish(title = 'wordcountapp', html_file='index.html',host="rpubs")
.libPaths( "")
publish(title = 'wordcountapp', html_file='index.html',host="rpubs")
publish_github(user="DataDan01",repo="https://github.com/DataDan01/Wordcount-App")
publish_github(user="DataDan01",repo="https://github.com/DataDan01/Wordcount-App")
options(rpubs.upload.method = "internal")
publish_rpubs(title = 'Wordcountapp', 'index.html')
